{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Model Development\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for fraud detection:\n",
    "\n",
    "1. **Data Generation & Loading**\n",
    "2. **Advanced Feature Engineering**\n",
    "3. **Individual Model Training & Evaluation**\n",
    "4. **Ensemble Model Development**\n",
    "5. **Model Explainability with SHAP**\n",
    "6. **Performance Analysis & Visualization**\n",
    "7. **Model Persistence**\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Sunny Nguyen  \n",
    "**Date**: September 2025  \n",
    "**Objective**: Build production-ready fraud detection system with 95%+ accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(f\"📅 Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing.generate_data import create_fraud_dataset\n",
    "from data_processing.feature_engineering import AdvancedFeatureEngineering\n",
    "from models.fraud_detector import (\n",
    "    RandomForestDetector, \n",
    "    XGBoostDetector, \n",
    "    LogisticRegressionDetector,\n",
    "    EnsembleFraudDetector\n",
    ")\n",
    "\n",
    "print(\"✅ Custom modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic fraud dataset\n",
    "print(\"🔄 Creating synthetic fraud dataset...\")\n",
    "\n",
    "# Create a substantial dataset for training\n",
    "DATASET_SIZE = 50000  # Increase for more robust training\n",
    "\n",
    "df = create_fraud_dataset(n_samples=DATASET_SIZE)\n",
    "\n",
    "print(f\"📊 Dataset created with {len(df):,} transactions\")\n",
    "print(f\"🎯 Fraud rate: {df['Class'].mean():.4f} ({df['Class'].mean()*100:.2f}%)\")\n",
    "print(f\"💰 Average transaction amount: ${df['Amount'].mean():.2f}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n📈 Dataset Overview:\")\n",
    "display(df.describe())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 2. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineering pipeline\n",
    "print(\"🔧 Initializing advanced feature engineering pipeline...\")\n",
    "\n",
    "fe_pipeline = AdvancedFeatureEngineering(target_column='Class')\n",
    "\n",
    "# Apply comprehensive feature engineering\n",
    "df_engineered = fe_pipeline.fit_transform(df)\n",
    "\n",
    "print(f\"\\n📊 Feature Engineering Results:\")\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"Engineered features: {df_engineered.shape[1]}\")\n",
    "print(f\"Features added: {df_engineered.shape[1] - df.shape[1]}\")\n",
    "\n",
    "# Show feature engineering summary\n",
    "feature_summary = fe_pipeline.get_feature_importance_summary()\n",
    "print(f\"\\n🎯 Selected features: {feature_summary['total_features_created']}\")\n",
    "print(f\"📝 Encoders fitted: {len(feature_summary['encoders_fitted'])}\")\n",
    "print(f\"📏 Scalers fitted: {len(feature_summary['scalers_fitted'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 3. Individual Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_engineered.drop('Class', axis=1)\n",
    "y = df_engineered['Class']\n",
    "\n",
    "print(f\"🎯 Final dataset for training:\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"Class distribution: {dict(y.value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 4. Ensemble Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble model\n",
    "print(\"🎯 Training Ensemble Fraud Detector...\")\n",
    "\n",
    "ensemble = EnsembleFraudDetector(random_state=42)\n",
    "ensemble.train(X, y, test_size=0.2, balance_data=True)\n",
    "\n",
    "print(f\"\\n✅ Ensemble training completed!\")\n",
    "print(f\"🎯 Ensemble F1 Score: {ensemble.ensemble_metrics['f1_score']:.4f}\")\n",
    "print(f\"🎯 Ensemble ROC-AUC: {ensemble.ensemble_metrics['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 5. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save feature engineering pipeline\n",
    "joblib.dump(fe_pipeline, '../models/feature_engineering_pipeline.pkl')\n",
    "\n",
    "# Save ensemble model\n",
    "ensemble.save_ensemble('../models/fraud_detection_ensemble.pkl')\n",
    "\n",
    "print(\"✅ All models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 6. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"🎯 FRAUD DETECTION MODEL TRAINING COMPLETE!\")\n",
    "print(f\"📊 Dataset: {len(df):,} transactions\")\n",
    "print(f\"🎯 Final Performance:\")\n",
    "for metric, value in ensemble.ensemble_metrics.items():\n",
    "    print(f\"  • {metric.replace('_', ' ').title()}: {value:.4f}\")\n",
    "print(\"🚀 Ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
